1. No, it doesn't work the same with regions as with files, we don't know that the reducer is running on the same region so there can be additional network traffic.

2. Instead of one additional chained mapper we could use two. The first chained mapper would compute the averages, and then the second mapper could compute the sums with the average values.

3. The data would get split into two chunks and we would get one set of stats for each chunk. R might not be useful in this case.

4. 

CREATE TABLE kdd2_phoenix (
  pk BIGINT PRIMARY KEY,
  info.fname VARCHAR,
  info.lname VARCHAR,
  sales.total DOUBLE,
  sales.last_sale DATE,
  sales.promo VARCHAR
);

UPSERT INTO kdd2_phoenix (pk, info.fname, info.lname, sales.total, sales.last_sale) VALUES (1, 'John', 'Smith', 321.23, to_date('2012-01-19'));

UPSERT INTO kdd2_phoenix (pk, info.fname, info.lname, sales.total, sales.promo) VALUES (2, 'Jane', 'Smith', 87.32, 'member');

5. It changed from a "LIENT 2-CHUNK PARALLEL 1-WAY FULL SCAN OVER kdd2-logs" to a "CLIENT 1-CHUNK PARALLEL 1-WAY RANGE SCAN OVER KDD2_PATH_INDEX ['/ksc.html']", which I think means it went from a full table scan to a scan over a subset of the data from an index.

6. It's one column. I think the row key is the path and the one column value is a list of applicable rows. If you make a query and want to use an index, first do a read on the index table, get the list applicable rows, and then make the query on the main table within those rows.